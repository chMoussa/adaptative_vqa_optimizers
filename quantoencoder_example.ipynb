{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab00b00",
   "metadata": {},
   "source": [
    "# Example of usage of an adaptative optimizer\n",
    "\n",
    "## Quantum Autoencoders\n",
    "\n",
    "In this notebook, we will present an example with quantum autoencoders. Here, we are given a set of states $\\{\\psi_i\\}_{i=1}^N$ and we want to compress such data by reducing the number of qubits needed to represent it. Given the regiser of qubits with $n_A + n_B$ qubits, one trains a gate sequence $U(\\theta)$ to compress the ensemble of states to $n_A$ qubits, $n_B$ qubits acting as trash. \n",
    "\n",
    "The task is to optimize the following cost:\n",
    "$\\sum_i  p_i Tr_{AB}[H_{L} U(\\theta) |\\psi_i \\rangle \\langle \\psi_i| U(\\theta)^\\dagger]$\n",
    "\n",
    "\n",
    "where $H_{L} = \\mathbb{1}_{AB} - \\frac{1}{n_B} \\sum_{j=1}^{n_B} \\mathbb{1}_{A} \\otimes |0 \\rangle \\langle 0|_j \\mathbb{1}_{\\bar{j}} $\n",
    "\n",
    "In our example, $\\{\\rho_i\\}_{i=1}^N$ will be taken from the collection of datasets available in Pennylane. We take several states obtained by running VQE for different bond lengths of the H2 molecule in the STO-3G basis. We obtain a dataset of 42 circuits as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9840822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from refoqus import Refoqus\n",
    "\n",
    "bondlengths = ['0.5', '0.54', '0.58', '0.62', '0.66', '0.7', '0.74', '0.742', '0.78', '0.82', '0.86', '0.9', '0.94', '0.98', '1.02', '1.06', '1.1', '1.14', '1.18', '1.22', '1.26', '1.3', '1.34', '1.38', '1.42', '1.46', '1.5', '1.54', '1.58', '1.62', '1.66', '1.7', '1.74', '1.78', '1.82', '1.86', '1.9', '1.94', '1.98', '2.02', '2.06', '2.1']\n",
    "moldataset = qml.data.load(\"qchem\", molname=\"H2\", basis=\"STO-3G\", bondlength=bondlengths)\n",
    "nbdatapoints = len(moldataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ef5a1",
   "metadata": {},
   "source": [
    "Now we set the coefficients as $- \\frac{1}{n_B}$ for the individual terms and of the hamiltonian of interest $H_L$ (note $1$ is a constant to be added later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a855d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbqbits = len(moldataset[0].hamiltonian.wires)\n",
    "nbtrash = nbqbits // 2\n",
    "coefficients_cost = [- 1.0 / float(nbtrash)] * nbtrash\n",
    "\n",
    "projector = np.zeros((2, 2))\n",
    "projector[0, 0] = 1\n",
    "\n",
    "\n",
    "quantoencoder_hamiltonian_term = [qml.Hermitian(projector,wires=i) for i in range(nbtrash)]\n",
    "\n",
    "hermitian_of_interest = qml.Hamiltonian(coefficients_cost, quantoencoder_hamiltonian_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebfe464",
   "metadata": {},
   "source": [
    "Next, we define functions to evaluate the true cost during optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0864ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "analytic_dev = qml.device(\"default.qubit\", wires=nbqbits, shots=None)\n",
    "\n",
    "@qml.qnode(analytic_dev)\n",
    "def cost_analytic_one_circuit(weights, index_datapoint):\n",
    "    \n",
    "    for op in moldataset[index_datapoint].vqe_gates:\n",
    "        qml.apply(op)\n",
    "        \n",
    "    StronglyEntanglingLayers(weights, wires=analytic_dev.wires)\n",
    "    return qml.expval(hermitian_of_interest)\n",
    "\n",
    "def cost_analytic_alldataset(weights):\n",
    "    \n",
    "    cost = 0.0\n",
    "    for m in range(nbdatapoints):\n",
    "        cost += cost_analytic_one_circuit(weights, m)\n",
    "    cost = 1.0 + cost / nbdatapoints\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c1e86f",
   "metadata": {},
   "source": [
    "Now, the ansatz is defined as with StronglyEntanglingLayers. We also sample initial values and the corresponding cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa3358d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.53662812, requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pennylane.templates.layers import StronglyEntanglingLayers\n",
    "\n",
    "# hyperparameter of ansatz\n",
    "num_layers = 3\n",
    "\n",
    "\n",
    "param_shape = StronglyEntanglingLayers.shape(n_layers=num_layers, n_wires=nbqbits)\n",
    "init_params = np.random.uniform(low=0.0, high=2*np.pi, size=param_shape, requires_grad=True)\n",
    "cost_analytic_alldataset(init_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1d361f",
   "metadata": {},
   "source": [
    "Our adaptative optimizer will be Refoqus where we provide the necessary arguments as follows and we perform niter iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f0f0d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: cost = 0.28589312845529313, shots_used = 144\n",
      "Step 2: cost = 0.3902475670708201, shots_used = 358\n",
      "Step 3: cost = 0.2384949719482743, shots_used = 602\n",
      "Step 4: cost = 0.18471718549820404, shots_used = 932\n",
      "Step 5: cost = 0.204221557099466, shots_used = 1204\n",
      "Step 6: cost = 0.12439188946059665, shots_used = 1544\n",
      "Step 7: cost = 0.23887756791453552, shots_used = 1974\n",
      "Step 8: cost = 0.1935431066370219, shots_used = 2424\n",
      "Step 9: cost = 0.1155112491091339, shots_used = 2946\n",
      "Step 10: cost = 0.08610532425513662, shots_used = 3644\n",
      "Step 11: cost = 0.049414360353539966, shots_used = 4752\n",
      "Step 12: cost = 0.05239088977482975, shots_used = 5846\n",
      "Step 13: cost = 0.017689726144136664, shots_used = 6732\n",
      "Step 14: cost = 0.033519943799980245, shots_used = 7364\n",
      "Step 15: cost = 0.042417887828340106, shots_used = 8358\n",
      "Step 16: cost = 0.03542620831077903, shots_used = 9668\n",
      "Step 17: cost = 0.03507831268548234, shots_used = 10174\n",
      "Step 18: cost = 0.018876921816949555, shots_used = 11428\n",
      "Step 19: cost = 0.013253963930710988, shots_used = 12138\n",
      "Step 20: cost = 0.02551843728956249, shots_used = 13166\n"
     ]
    }
   ],
   "source": [
    "opt = Refoqus(nbqbits, [m.vqe_gates for m in moldataset], quantoencoder_hamiltonian_term, coefficients_cost, param_shape, min_shots=2)\n",
    "params = init_params\n",
    "niter = 20\n",
    "\n",
    "cost_refoqus = [cost_analytic_alldataset(params)]\n",
    "shots_refoqus = [0]\n",
    "\n",
    "for i in range(niter):\n",
    "    params = opt.step(params)\n",
    "    cost_refoqus.append(cost_analytic_alldataset(params))\n",
    "    shots_refoqus.append(opt.shots_used)\n",
    "    print(f\"Step {i+1}: cost = {cost_refoqus[-1]}, shots_used = {shots_refoqus[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec187f46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hackenv]",
   "language": "python",
   "name": "conda-env-hackenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
